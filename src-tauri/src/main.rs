#![cfg_attr(not(debug_assertions), windows_subsystem = "windows")]

use tauri::command;
use reqwest::Client;
use serde_json::json;

// ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯ï¼ˆã¨ã‚Šã‚ãˆãšOllamaãŒèµ·ãã¦ã‚‹ã‹ï¼‰
#[command]
async fn is_model_loaded() -> bool {
    println!("ğŸ•µï¸ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰çŠ¶æ…‹ç¢ºèªä¸­...");
    match reqwest::get("http://localhost:11434").await {
        Ok(_) => {
            println!("âœ… Ollama å¿œç­”ã‚ã‚Šã€‚ãƒ¢ãƒ‡ãƒ«èµ·å‹•å¯èƒ½ã€‚");
            true
        },
        Err(e) => {
            println!("âŒ Ollama ã‹ã‚‰ã®å¿œç­”ãªã—: {}", e);
            false
        },
    }
}

// ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
#[command]
async fn generate_text(prompt: String) -> Result<String, String> {
    println!("ğŸ§  generate_text å‘¼ã³å‡ºã—: prompt = {}", prompt);

    let client = Client::new();
    let body = json!({
        "model": "gemma3:4b", // ãƒ¢ãƒ‡ãƒ«åï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰ãˆã¦ï¼‰
        "prompt": prompt,
        "stream": false
    });

    let res = client
        .post("http://localhost:11434/api/generate")
        .json(&body)
        .send()
        .await
        .map_err(|e| format!("âŒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {}", e))?;

    let json: serde_json::Value = res
        .json()
        .await
        .map_err(|e| format!("âŒ JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—: {}", e))?;

    if let Some(resp) = json["response"].as_str() {
        println!("ğŸ“¦ å¿œç­”å–å¾—æˆåŠŸ");
        Ok(resp.to_string())
    } else {
        println!("âš ï¸ å¿œç­”ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãªã—: {:?}", json);
        Err("å¿œç­”ãªã—".into())
    }
}

// AIå¿œç­”ç”Ÿæˆï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆæˆï¼‹generate_textï¼‰
#[command]
async fn generate_ai_response(
    name: String,
    role: String,
    description: String,
    conversation_history: String,
    query: String,
) -> Result<String, String> {
    println!("ğŸ¤– generate_ai_response å‘¼ã³å‡ºã—");
    let prompt = format!(
        "ã‚ãªãŸã¯{name}ã¨ã„ã†åå‰ã®{role}ã§ã™ã€‚{description}\n\
         ã“ã‚Œã¾ã§ã®ä¼šè©±:\n{conversation_history}\n\
         ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {query}\nã‚ãªãŸã®å¿œç­”:"
    );

    generate_text(prompt).await
}

fn main() {
    println!("ğŸš€ Tauri ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰èµ·å‹•");

    tauri::Builder::default()
        .invoke_handler(tauri::generate_handler![
            is_model_loaded,
            generate_text,
            generate_ai_response
        ])
        .run(tauri::generate_context!())
        .expect("Tauri èµ·å‹•å¤±æ•—");
}